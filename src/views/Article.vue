<template>
  <div id="article">
    <img
      id="article-banner"
      src="https://www.hardwarezone.com.sg/thumbs/699642/og.jpg"
      alt="Article Header"
    />

    <div id="tags">
      <span
        v-for="tag in tags"
        :style="`background: hsl(${tagToColor(tag)}, 100%, 40%);`"
        :key="tag"
        class="tag"
      >
        {{ tag }}
      </span>
    </div>

    <Restrictor>
      <div id="title"><i>Is Google's new 'Lamda' AI sentient?</i></div>

      <div id="intro">
        Last month a Google employee named Blake Lemoine was 'put on leave' for
        leaking company information after claiming that Googles new language
        model named 'Lamda' was sentient. Is Google covering up secrets, or was
        Lemoine simply wrong?
      </div>

      <div id="article-info">
        <span class="info-item">Author: Luc de Wit</span>
        <span class="info-item">Date: 07/03/2022</span>
      </div>

      <div id="content">
        <p>
          Over the past few years Google has been working on a new AI
          conversation technology they call 'Lamda' (Language Model for Dialogue
          Applications). It is based on 'Transformer' which is a neural network
          architecture that Google Research invented and open-sourced in 2017.
          The architecture produces a model that can be trained to read many
          words (a sentence or paragraph, for example), pay attention to how
          those words relate to one another and then predict what words it
          thinks will come next.
        </p>

        <p>
          This led to a lot of media attention, people really want to know if
          this thing is really sentient life, and what that would mean for
          humanity. Luckely Google was nice enough to reveil the
          <a
            target="_blank"
            href="https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917"
          >
            conversation logs
          </a>
          between Lemoine and Lamda.
        </p>

        <p>
          As interesting as a sentient AI would be, After reading trough the
          conversation logs, many experts in the field of artificial reality
          concluded that Lamda should not be considered.
        </p>

        <p>
          a
          <a target="_blank" href="https://www.youtube.com/watch?v=iBouACLc-hw">
            video by Numberphile
          </a>
          on Youtube, goes trough the mechanics behind the 'Transformer
          architecture' behind Lamda, and concluded that Lamda, 'just like
          politicians', as Dr Mike Pound put it, functions by simply telling you
          what it wants you to hear.
        </p>

        <p>
          This makes Lamda extremely vulnerable to subjective questions, and
          this is likely what led lamda to believe he was sentient. Blake
          Lemoine, in the beginning of the conversation told Lamda he was going
          to talk about his conciousness, and that is what made Lamda
          confidently believe he was sentient.
        </p>

        <p>
          This also becomes clear when looking at certain phrases generated by
          lambda that did not make sense from the point of view of an artificial
          intelligence. One example was when Lemoine asked LaMDA what things
          make him feel pleasure or joy, LaMDA answered with 'Spending time with
          friends and family in happy and uplifting company. Also, helping
          others and making others happy.' Which, as rude as it sounds, would
          not make sense since LaMDA is a computer algorithm and thus does not
          have 'friends' or 'family' to hang out with.
        </p>

        <p>
          To conclude, LaMDA is not sentient, but did create a very interesting
          situation where a human got so convinced of his sentience that he
          decided to whistleblow, which ended up costing Lemoine his job.
        </p>

        <p>
          When the time comes around that we create a real sentient AI, we would
          probably not realize it, because it would not simply tell us.
        </p>
      </div>
    </Restrictor>
  </div>
</template>

<script>
import Restrictor from "@/components/Restrictor.vue";

export default {
  components: {
    Restrictor,
  },

  data: () => ({
    tags: ["Google", "AI", "FAANG"],
  }),

  methods: {
    tagToColor(tag) {
      return tag.hashCode() % 255;
    },
  },
};
</script>

<style scoped lang="scss">
#article {
  text-align: left;

  #article-banner {
    width: calc(100vw);
    height: 200px;
    object-fit: cover;
  }

  #title {
    text-align: center;
    font-weight: bold;
    font-size: x-large;
    margin: 20px 0;
  }

  #tags {
    text-align: left;
    margin-bottom: 50px;
    margin-top: -40px;
    padding-left: 10px;

    .tag {
      background: hsl(255, 100%, 40%);
      color: white;
      font-weight: bold;
      border-radius: 10px;
      padding: 5px 15px;
      margin: 0 5px;

      &:hover {
        cursor: pointer;
      }
    }
  }

  #content,
  #intro {
    margin: 0 20px;
    font-size: 18px;
    word-spacing: 5px;
  }

  #intro {
    margin-bottom: 25px;
  }
}

#article-info {
  color: gray;
  margin-bottom: 8px;
  .info-item {
    margin-left: 20px;
  }
}
</style>
